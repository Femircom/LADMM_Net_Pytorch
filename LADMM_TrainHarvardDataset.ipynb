{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMzd-RxcPG7z"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1652,
     "status": "ok",
     "timestamp": 1613559351111,
     "user": {
      "displayName": "Juan Ramírez",
      "photoUrl": "",
      "userId": "10349054824212831472"
     },
     "user_tz": -60
    },
    "id": "rsGXqAz8PPcN",
    "outputId": "36cb1e1c-9fa9-46db-e941-2c6de7b1596a"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "#drive.mount('/content/gdrive/')\n",
    "drive.mount(\"/content/gdrive/\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1647,
     "status": "ok",
     "timestamp": 1613559351111,
     "user": {
      "displayName": "Juan Ramírez",
      "photoUrl": "",
      "userId": "10349054824212831472"
     },
     "user_tz": -60
    },
    "id": "0xuqE7P2Pp7t",
    "outputId": "3786ed1d-a0f0-4c0d-90e2-f04651ce1cbe"
   },
   "outputs": [],
   "source": [
    "%cd \"/content/gdrive/My Drive/Colab Notebooks/LADMM_Net_Pytorch\"\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2643,
     "status": "ok",
     "timestamp": 1613559352111,
     "user": {
      "displayName": "Juan Ramírez",
      "photoUrl": "",
      "userId": "10349054824212831472"
     },
     "user_tz": -60
    },
    "id": "vHzrw1PePx5V"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "\n",
    "# our libraries\n",
    "from utils import featurefusionpkg as ff\n",
    "\n",
    "from models.LadmmNet import LADMMcsifusionfastNet\n",
    "# Pytorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "gpu_list = '0'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_list\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRQCOuAhSFkJ"
   },
   "source": [
    "# Measurement matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6136,
     "status": "ok",
     "timestamp": 1613559355606,
     "user": {
      "displayName": "Juan Ramírez",
      "photoUrl": "",
      "userId": "10349054824212831472"
     },
     "user_tz": -60
    },
    "id": "FJSePPPcSSjK"
   },
   "outputs": [],
   "source": [
    "# Loading hyperspectral coded aperture\n",
    "fname1       = 'cca_hs.mat'\n",
    "data_path    = os.path.join(os.getcwd(),'data/Harvard/csi_measurements/25')\n",
    "#data_path    = os.path.join(os.getcwd(),'data/Harvard/csi_measurements/375')\n",
    "cca_hs       = sio.loadmat(os.path.join(data_path, fname1))['cca_hs']\n",
    "shots_hs, M_hs, N_hs, L = cca_hs.shape\n",
    "ccahs_np     = np.zeros((shots_hs*M_hs*N_hs*L))\n",
    "for i in range(0,shots_hs):\n",
    "  ccahs_np[i*M_hs*N_hs*L:(i+1)*M_hs*N_hs*L] = cca_hs[i,:,:,:].reshape((M_hs*N_hs*L),order='F')\n",
    "ccahs        = torch.from_numpy(np.double(ccahs_np)).type(torch.FloatTensor)\n",
    "del cca_hs, ccahs_np\n",
    "ccahs = ccahs.view(-1,L,M_hs,N_hs).to(device)\n",
    "\n",
    "# Loading multispectral coded aperture\n",
    "fname1       = 'cca_ms.mat'\n",
    "cca_ms       = sio.loadmat(os.path.join(data_path, fname1))['cca_ms']\n",
    "shots_ms, M, N, L_ms = cca_ms.shape\n",
    "ccams_np     = np.zeros((shots_ms*M*N*L_ms))\n",
    "for i in range(0,shots_ms):\n",
    "  ccams_np[i*M*N*L_ms:(i+1)*M*N*L_ms] = cca_ms[i,:,:,:].reshape((M*N*L_ms),order='F')\n",
    "ccams        = torch.from_numpy(np.double(ccams_np)).type(torch.FloatTensor)\n",
    "del cca_ms, ccams_np\n",
    "ccams = ccams.view(-1,L_ms,M,N).to(device)\n",
    "\n",
    "p = 4\n",
    "q = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QX09iovOblld"
   },
   "source": [
    "# LADMM parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6136,
     "status": "ok",
     "timestamp": 1613559355608,
     "user": {
      "displayName": "Juan Ramírez",
      "photoUrl": "",
      "userId": "10349054824212831472"
     },
     "user_tz": -60
    },
    "id": "ivEsq0T4b0_l"
   },
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "\n",
    "layer_num               = 10\n",
    "learning_rate           = 0.0005\n",
    "epochs                  = 256\n",
    "epochs                  = epochs + 1\n",
    "num_training_samples    = 48\n",
    "num_samples             = 48\n",
    "batch_size              = 1\n",
    "compression_ratio       = 50\n",
    "\n",
    "model     = LADMMcsifusionfastNet(layer_num)\n",
    "model     = nn.DataParallel(model)\n",
    "model     = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "indices         = np.random.permutation(num_samples)\n",
    "train_indices   = indices[:num_training_samples]\n",
    "sample_path     = os.path.join(os.getcwd(),'data/Harvard/csi_measurements/%d'%(compression_ratio))\n",
    "data_path       = os.path.join(os.getcwd(),'data/Harvard/high_resolution_images')\n",
    "model_dir       = \"./train_parameters/Harvard/LADMM_Net_layer_%d_ratio_%d\" % (layer_num, compression_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnFw4wIvf7bD"
   },
   "source": [
    "# Training stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 104949,
     "status": "error",
     "timestamp": 1613559454430,
     "user": {
      "displayName": "Juan Ramírez",
      "photoUrl": "",
      "userId": "10349054824212831472"
     },
     "user_tz": -60
    },
    "id": "ZnekgvXkgAso",
    "outputId": "3081cac1-cb6a-443b-a16c-3900f13c1d45"
   },
   "outputs": [],
   "source": [
    "psnr = np.zeros(epochs)\n",
    "def SpectralDegradationFilter(window_size, L, q):\n",
    "  kernel = torch.zeros((L//q,L,window_size,window_size))\n",
    "  for i in range(0,L//q):\n",
    "    kernel[i,i*q:(i+1)*(q),window_size//2,window_size//2] = 1/q\n",
    "  return kernel\n",
    "\n",
    "def ProjectionFilter(window_size, L):\n",
    "  kernel = torch.zeros((1,L,window_size,window_size))\n",
    "  kernel[0,1:L,window_size//2,window_size//2] = 1\n",
    "  return kernel\n",
    "\n",
    "def SpectralUpsamplingFilter(window_size, q, L):\n",
    "  kernel = torch.zeros((L,L//q,window_size,window_size))\n",
    "  for i in range(0,L//q):\n",
    "    for j in range(0,q):\n",
    "      kernel[i*q+j,i,window_size//2,window_size//2] = 1 \n",
    "  return kernel\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch_i in range(0, epochs):\n",
    "    batch_iter  = num_training_samples // batch_size\n",
    "    psnr_b      = np.zeros(batch_iter)\n",
    "    for data in range(0,batch_iter):\n",
    "      #print(epoch_i, data)\n",
    "      new_indices = train_indices[data*batch_size: data*batch_size + batch_size]       \n",
    "            \n",
    "      fnp = np.zeros((M*N*L*batch_size))\n",
    "      for bs in range(0, batch_size):\n",
    "      # Load compressive measurements\n",
    "        fpointer        = new_indices[bs] + 1\n",
    "        fsamples_ms     = 'hri_%03d.mat' % (fpointer)\n",
    "        hri             = sio.loadmat(os.path.join(data_path, fsamples_ms))['foo']\n",
    "        fnp[bs*M*N*L:(bs+1)*M*N*L] = hri.reshape((M*N*L),order='F')\n",
    "\n",
    "      f = torch.from_numpy(np.double(fnp)).type(torch.FloatTensor)*(1/255.0)\n",
    "      f = f.view(-1,L,M,N).to(device)\n",
    "\n",
    "      # Acquisition process of the HS compressive measurements\n",
    "      hs_deg        = nn.AvgPool2d(p)\n",
    "      shot_data_hs  = torch.mean(torch.mul(ccahs,hs_deg(f).repeat(shots_hs, 1, 1, 1)),(1))\n",
    "      shot_data_hs  = shot_data_hs * (1/torch.max(shot_data_hs))\n",
    "      #shot_data_hs  = shot_data_hs + (0.01 * torch.randn((shot_data_hs.size())).to(device)) \n",
    "\n",
    "      # HS measurement matrix transpose\n",
    "      HTyhs         = F.interpolate(torch.mean(torch.mul(shot_data_hs.view(shots_hs,1,M_hs,N_hs).repeat(1,L,1,1), ccahs),(0)).view(1,L,M_hs,N_hs),scale_factor=(p,p))\n",
    "#      HTyhs2         = F.interpolate(torch.mean(shot_data_hs,(0)).repeat(L,1,1).view(1,L,M_hs,N_hs),scale_factor=(p,p))\n",
    "\n",
    "      # Acquisition process of the MS compressive measurements\n",
    "      kernel = SpectralDegradationFilter(3,L,q).to(device)\n",
    "      shot_data_ms  = torch.mean(torch.mul(ccams,F.conv2d(f, kernel, padding=1).repeat(shots_ms, 1, 1, 1)),(1))\n",
    "      shot_data_ms  = shot_data_ms * (1/torch.max(shot_data_ms))\n",
    "      #shot_data_ms  = shot_data_ms + (0.01 * torch.randn((shot_data_ms.size())).to(device))\n",
    "\n",
    "      # MS measurement matrix transpose\n",
    "#      HTyms         = torch.mean(shot_data_ms,(0)).repeat(L,1,1).view(1,L,M,N)\n",
    "      upsamp = SpectralUpsamplingFilter(3,q,L_ms*q).to(device)\n",
    "      HTyms  = F.conv2d(torch.mean(torch.mul(shot_data_ms.view(shots_ms,1,M,N).repeat(1,L_ms,1,1), ccams),(0)).view(1,L_ms,M,N),upsamp, padding=1)\n",
    "#      print(shot_data_ms.shape,ccams.shape, HTyms.shape)\n",
    "#      plt.imshow(HTyhs[0,0,:,:].cpu())\n",
    "\n",
    "      [x_output, loss_layers_sym] = model(ccahs, ccams, HTyhs, HTyms, M, N, L, p, q, shots_hs, shots_ms)\n",
    "      del shot_data_hs, shot_data_ms, HTyhs, HTyms\n",
    "\n",
    "      loss_constraint = torch.mean(torch.pow(loss_layers_sym[0], 2))   \n",
    "      loss_discrepancy  = torch.mean(torch.pow(x_output - f, 2))\n",
    "      del x_output, f, loss_layers_sym\n",
    "\n",
    "      loss_all = torch.mul(0.90, loss_discrepancy) + torch.mul(0.10, loss_constraint)\n",
    "      psnr_batch = torch.mul(10, torch.log10(torch.div(1.0, loss_discrepancy))) \n",
    "      psnr_b[data] = psnr_batch;\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss_all.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      output_data = \"[epoch %03d/%03d batch %02d/%02d] total loss: %.4f, MSE: %.4f,  invertibility error: %.4f, PSNR: %.2f\\n\" % (epoch_i, epochs-1, data+1, num_training_samples, loss_all.item(), loss_discrepancy.item(), loss_constraint, psnr_batch)\n",
    "      print(output_data)\n",
    "    psnr[epoch_i]= np.mean(psnr_b)\n",
    "    print('Epoch mean PSNR[dB]: %.2f'%(psnr[epoch_i]))\n",
    "    sio.savemat('psnr_vs_epochs_layer_%d_ratio_%d.mat'%(layer_num, compression_ratio),{\"psnr_vs_epochs\":psnr})\n",
    "    if epoch_i % 16 == 0:\n",
    "      torch.save(model.state_dict(), \"./%s/net_params_%d.pkl\" % (model_dir, epoch_i))\n",
    "        \n",
    "plt.figure()\n",
    "plt.plot(psnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 104943,
     "status": "aborted",
     "timestamp": 1613559454427,
     "user": {
      "displayName": "Juan Ramírez",
      "photoUrl": "",
      "userId": "10349054824212831472"
     },
     "user_tz": -60
    },
    "id": "ogEkQ7bBkNJQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LADMM_TrainHarvardDataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
